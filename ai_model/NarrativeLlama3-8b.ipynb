{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36f70cb4-4eb9-4bbd-b8a2-18bf9ef3562c",
   "metadata": {
    "id": "36f70cb4-4eb9-4bbd-b8a2-18bf9ef3562c"
   },
   "source": [
    "# Working with Narrative Data\n",
    "\n",
    "This notebook illustrates some examples of working with narrative text data using small, local language models.\n",
    "\n",
    "## Running this notebook on a newer MacBook with Apple Silicon Chip\n",
    "\n",
    "You will need an environment with Python and Jupyter installed. To create an environment with Anaconda for Python 3.12, execute: \n",
    "\n",
    "```\n",
    "conda create --name llm-narrative python=3.12\n",
    "conda activate llm-narrative\n",
    "conda install jupyter\n",
    "jupyter notebook\n",
    "```\n",
    "\n",
    "## Running this notebook on older MacBooks or any other machine\n",
    "\n",
    "Please run this script on [Google Colab](https://colab.research.google.com/). After opening the notebook there, please change the settings to using a GPU, check [here](https://www.geeksforgeeks.org/how-to-use-gpu-in-google-colab/) for instructions on how to do that.\n",
    "\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T02:23:30.032991Z",
     "start_time": "2024-07-30T02:23:30.025437Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## check computer platform\n",
    "import platform\n",
    "print(platform.processor())"
   ],
   "id": "3bc1ba1d2fa7cd89",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel64 Family 6 Model 165 Stepping 2, GenuineIntel\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "f0b3c0d5-b1f6-4937-9cfa-4d74de9fc7d2",
   "metadata": {
    "id": "f0b3c0d5-b1f6-4937-9cfa-4d74de9fc7d2"
   },
   "source": [
    "### Install required libraries\n",
    "\n",
    "For the newer MacBooks with Apple Chips we will use `mlx-lm` to load a small, quantized version of the Llama 3 8b instruct model, so that it can run on a single laptop (https://ollama.com/library/llama3). For older MacBooks and other machines we will use a quantized version of the model provided by the hugging face community (https://huggingface.co/astronomer/Llama-3-8B-Instruct-GPTQ-4-Bit).\n",
    "\n",
    "Depending on the machine, different packages are required and will be installed below."
   ]
  },
  {
   "cell_type": "code",
   "id": "e2e769d5-d3c8-405c-8a05-e5dd1ec7b23c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e2e769d5-d3c8-405c-8a05-e5dd1ec7b23c",
    "outputId": "bdbaad62-1046-41f0-d7e9-2737146ef73c",
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-07-30T02:23:34.654341Z",
     "start_time": "2024-07-30T02:23:30.033986Z"
    }
   },
   "source": [
    "import platform\n",
    "\n",
    "# for the newer MacBooks with the Apple Chip\n",
    "# changed for testing but change back later\n",
    "if platform.processor() == 'arm':\n",
    "    ! pip install mlx-lm torch transformers\n",
    "# for all other machines\n",
    "else:\n",
    "    ! pip install torch transformers optimum accelerate auto-gptq bitsandbytes"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in e:\\apps\\anaconda\\envs\\rdf\\lib\\site-packages (2.4.0)\n",
      "Requirement already satisfied: transformers in e:\\apps\\anaconda\\envs\\rdf\\lib\\site-packages (4.42.4)\n",
      "Requirement already satisfied: optimum in e:\\apps\\anaconda\\envs\\rdf\\lib\\site-packages (1.21.2)\n",
      "Requirement already satisfied: accelerate in e:\\apps\\anaconda\\envs\\rdf\\lib\\site-packages (0.33.0)\n",
      "Requirement already satisfied: auto-gptq in e:\\apps\\anaconda\\envs\\rdf\\lib\\site-packages (0.7.1)\n",
      "Requirement already satisfied: bitsandbytes in e:\\apps\\anaconda\\envs\\rdf\\lib\\site-packages (0.43.2)\n",
      "Requirement already satisfied: filelock in e:\\apps\\anaconda\\envs\\rdf\\lib\\site-packages (from torch) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in e:\\apps\\anaconda\\envs\\rdf\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in e:\\apps\\anaconda\\envs\\rdf\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: networkx in e:\\apps\\anaconda\\envs\\rdf\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in e:\\apps\\anaconda\\envs\\rdf\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in e:\\apps\\anaconda\\envs\\rdf\\lib\\site-packages (from torch) (2024.5.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in e:\\apps\\anaconda\\envs\\rdf\\lib\\site-packages (from transformers) (0.24.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17 in e:\\apps\\anaconda\\envs\\rdf\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\apps\\anaconda\\envs\\rdf\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in e:\\apps\\anaconda\\envs\\rdf\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in e:\\apps\\anaconda\\envs\\rdf\\lib\\site-packages (from transformers) (2024.7.24)\n",
      "Requirement already satisfied: requests in e:\\apps\\anaconda\\envs\\rdf\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in e:\\apps\\anaconda\\envs\\rdf\\lib\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in e:\\apps\\anaconda\\envs\\rdf\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in e:\\apps\\anaconda\\envs\\rdf\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: coloredlogs in e:\\apps\\anaconda\\envs\\rdf\\lib\\site-packages (from optimum) (15.0.1)\n",
      "Requirement already satisfied: datasets in e:\\apps\\anaconda\\envs\\rdf\\lib\\site-packages (from optimum) (2.20.0)\n",
      "Requirement already satisfied: psutil in e:\\apps\\anaconda\\envs\\rdf\\lib\\site-packages (from accelerate) (6.0.0)\n",
      "Requirement already satisfied: sentencepiece in e:\\apps\\anaconda\\envs\\rdf\\lib\\site-packages (from auto-gptq) (0.2.0)\n",
      "Requirement already satisfied: rouge in e:\\apps\\anaconda\\envs\\rdf\\lib\\site-packages (from auto-gptq) (1.0.1)\n",
      "Requirement already satisfied: gekko in e:\\apps\\anaconda\\envs\\rdf\\lib\\site-packages (from auto-gptq) (1.2.1)\n",
      "Requirement already satisfied: peft>=0.5.0 in e:\\apps\\anaconda\\envs\\rdf\\lib\\site-packages (from auto-gptq) (0.12.0)\n",
      "Requirement already satisfied: colorama in e:\\apps\\anaconda\\envs\\rdf\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: protobuf in e:\\apps\\anaconda\\envs\\rdf\\lib\\site-packages (from transformers[sentencepiece]<4.43.0,>=4.26.0->optimum) (5.27.2)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in e:\\apps\\anaconda\\envs\\rdf\\lib\\site-packages (from coloredlogs->optimum) (10.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in e:\\apps\\anaconda\\envs\\rdf\\lib\\site-packages (from datasets->optimum) (17.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in e:\\apps\\anaconda\\envs\\rdf\\lib\\site-packages (from datasets->optimum) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in e:\\apps\\anaconda\\envs\\rdf\\lib\\site-packages (from datasets->optimum) (0.3.8)\n",
      "Requirement already satisfied: pandas in e:\\apps\\anaconda\\envs\\rdf\\lib\\site-packages (from datasets->optimum) (2.2.2)\n",
      "Requirement already satisfied: xxhash in e:\\apps\\anaconda\\envs\\rdf\\lib\\site-packages (from datasets->optimum) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in e:\\apps\\anaconda\\envs\\rdf\\lib\\site-packages (from datasets->optimum) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in e:\\apps\\anaconda\\envs\\rdf\\lib\\site-packages (from datasets->optimum) (3.9.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\apps\\anaconda\\envs\\rdf\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\apps\\anaconda\\envs\\rdf\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\apps\\anaconda\\envs\\rdf\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\apps\\anaconda\\envs\\rdf\\lib\\site-packages (from requests->transformers) (2024.6.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\apps\\anaconda\\envs\\rdf\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: six in e:\\apps\\anaconda\\envs\\rdf\\lib\\site-packages (from rouge->auto-gptq) (1.16.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in e:\\apps\\anaconda\\envs\\rdf\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in e:\\apps\\anaconda\\envs\\rdf\\lib\\site-packages (from aiohttp->datasets->optimum) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in e:\\apps\\anaconda\\envs\\rdf\\lib\\site-packages (from aiohttp->datasets->optimum) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in e:\\apps\\anaconda\\envs\\rdf\\lib\\site-packages (from aiohttp->datasets->optimum) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in e:\\apps\\anaconda\\envs\\rdf\\lib\\site-packages (from aiohttp->datasets->optimum) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in e:\\apps\\anaconda\\envs\\rdf\\lib\\site-packages (from aiohttp->datasets->optimum) (1.9.4)\n",
      "Requirement already satisfied: pyreadline3 in e:\\apps\\anaconda\\envs\\rdf\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->optimum) (3.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in e:\\apps\\anaconda\\envs\\rdf\\lib\\site-packages (from pandas->datasets->optimum) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\apps\\anaconda\\envs\\rdf\\lib\\site-packages (from pandas->datasets->optimum) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in e:\\apps\\anaconda\\envs\\rdf\\lib\\site-packages (from pandas->datasets->optimum) (2024.1)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "fac10bee-5c79-472d-a39a-7ff9326cdd0f",
   "metadata": {
    "id": "fac10bee-5c79-472d-a39a-7ff9326cdd0f"
   },
   "source": [
    "### Install Llama 3 - 8b\n",
    "Next we install the quantized version of the Llama 8b language model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "1bac8054-5e69-432b-9b8e-9372b69084ac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "id": "1bac8054-5e69-432b-9b8e-9372b69084ac",
    "outputId": "5b40de9a-b209-4cc3-f203-edfc42f8f35f",
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-07-30T02:23:37.191879Z",
     "start_time": "2024-07-30T02:23:34.655335Z"
    }
   },
   "source": [
    "if platform.processor() == 'arm':\n",
    "    from mlx_lm import load, generate\n",
    "    model, tokenizer = load(\"mlx-community/Meta-Llama-3-8B-Instruct-4bit\")\n",
    "else:\n",
    "    from transformers import AutoTokenizer, AutoModelForCausalLM, AutoConfig\n",
    "    import torch\n",
    "\n",
    "    MODEL_ID=\"astronomer/Llama-3-8B-Instruct-GPTQ-4-Bit\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"astronomer/Llama-3-8B-Instruct-GPTQ-4-Bit\")\n",
    "\n",
    "    config = AutoConfig.from_pretrained(MODEL_ID)\n",
    "    config.quantization_config[\"disable_exllama\"] = False\n",
    "    config.quantization_config[\"exllama_config\"] = {\"version\":2}\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "            MODEL_ID, \n",
    "            device_map='auto', \n",
    "            torch_dtype=torch.bfloat16, \n",
    "            trust_remote_code=True, \n",
    "            # low_cpu_mem_usage=True,\n",
    "            # load_in_4bit=True,\n",
    "            config=config,\n",
    "        )"
   ],
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 126] 找不到指定的模块。 Error loading \"E:\\Apps\\anaconda\\envs\\rdf\\Lib\\site-packages\\torch\\lib\\fbgemm.dll\" or one of its dependencies.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 5\u001B[0m\n\u001B[0;32m      3\u001B[0m     model, tokenizer \u001B[38;5;241m=\u001B[39m load(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmlx-community/Meta-Llama-3-8B-Instruct-4bit\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m----> 5\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtransformers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AutoTokenizer, AutoModelForCausalLM, AutoConfig\n\u001B[0;32m      6\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[0;32m      8\u001B[0m     MODEL_ID\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mastronomer/Llama-3-8B-Instruct-GPTQ-4-Bit\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[1;32mE:\\Apps\\anaconda\\envs\\rdf\\Lib\\site-packages\\transformers\\__init__.py:26\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtyping\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m TYPE_CHECKING\n\u001B[0;32m     25\u001B[0m \u001B[38;5;66;03m# Check the dependencies satisfy the minimal versions required.\u001B[39;00m\n\u001B[1;32m---> 26\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m dependency_versions_check\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     28\u001B[0m     OptionalDependencyNotAvailable,\n\u001B[0;32m     29\u001B[0m     _LazyModule,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     48\u001B[0m     logging,\n\u001B[0;32m     49\u001B[0m )\n\u001B[0;32m     52\u001B[0m logger \u001B[38;5;241m=\u001B[39m logging\u001B[38;5;241m.\u001B[39mget_logger(\u001B[38;5;18m__name__\u001B[39m)  \u001B[38;5;66;03m# pylint: disable=invalid-name\u001B[39;00m\n",
      "File \u001B[1;32mE:\\Apps\\anaconda\\envs\\rdf\\Lib\\site-packages\\transformers\\dependency_versions_check.py:16\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Copyright 2020 The HuggingFace Team. All rights reserved.\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;66;03m# See the License for the specific language governing permissions and\u001B[39;00m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;66;03m# limitations under the License.\u001B[39;00m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdependency_versions_table\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m deps\n\u001B[1;32m---> 16\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mversions\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m require_version, require_version_core\n\u001B[0;32m     19\u001B[0m \u001B[38;5;66;03m# define which module versions we always want to check at run time\u001B[39;00m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;66;03m# (usually the ones defined in `install_requires` in setup.py)\u001B[39;00m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;66;03m# order specific notes:\u001B[39;00m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;66;03m# - tqdm must be checked before tokenizers\u001B[39;00m\n\u001B[0;32m     25\u001B[0m pkgs_to_check_at_runtime \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m     26\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpython\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     27\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtqdm\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     37\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpyyaml\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     38\u001B[0m ]\n",
      "File \u001B[1;32mE:\\Apps\\anaconda\\envs\\rdf\\Lib\\site-packages\\transformers\\utils\\__init__.py:34\u001B[0m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mconstants\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD, IMAGENET_STANDARD_MEAN, IMAGENET_STANDARD_STD\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdoc\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     27\u001B[0m     add_code_sample_docstrings,\n\u001B[0;32m     28\u001B[0m     add_end_docstrings,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     32\u001B[0m     replace_return_docstrings,\n\u001B[0;32m     33\u001B[0m )\n\u001B[1;32m---> 34\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgeneric\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     35\u001B[0m     ContextManagers,\n\u001B[0;32m     36\u001B[0m     ExplicitEnum,\n\u001B[0;32m     37\u001B[0m     ModelOutput,\n\u001B[0;32m     38\u001B[0m     PaddingStrategy,\n\u001B[0;32m     39\u001B[0m     TensorType,\n\u001B[0;32m     40\u001B[0m     add_model_info_to_auto_map,\n\u001B[0;32m     41\u001B[0m     add_model_info_to_custom_pipelines,\n\u001B[0;32m     42\u001B[0m     cached_property,\n\u001B[0;32m     43\u001B[0m     can_return_loss,\n\u001B[0;32m     44\u001B[0m     expand_dims,\n\u001B[0;32m     45\u001B[0m     filter_out_non_signature_kwargs,\n\u001B[0;32m     46\u001B[0m     find_labels,\n\u001B[0;32m     47\u001B[0m     flatten_dict,\n\u001B[0;32m     48\u001B[0m     infer_framework,\n\u001B[0;32m     49\u001B[0m     is_jax_tensor,\n\u001B[0;32m     50\u001B[0m     is_numpy_array,\n\u001B[0;32m     51\u001B[0m     is_tensor,\n\u001B[0;32m     52\u001B[0m     is_tf_symbolic_tensor,\n\u001B[0;32m     53\u001B[0m     is_tf_tensor,\n\u001B[0;32m     54\u001B[0m     is_torch_device,\n\u001B[0;32m     55\u001B[0m     is_torch_dtype,\n\u001B[0;32m     56\u001B[0m     is_torch_tensor,\n\u001B[0;32m     57\u001B[0m     reshape,\n\u001B[0;32m     58\u001B[0m     squeeze,\n\u001B[0;32m     59\u001B[0m     strtobool,\n\u001B[0;32m     60\u001B[0m     tensor_size,\n\u001B[0;32m     61\u001B[0m     to_numpy,\n\u001B[0;32m     62\u001B[0m     to_py_obj,\n\u001B[0;32m     63\u001B[0m     torch_float,\n\u001B[0;32m     64\u001B[0m     torch_int,\n\u001B[0;32m     65\u001B[0m     transpose,\n\u001B[0;32m     66\u001B[0m     working_or_temp_dir,\n\u001B[0;32m     67\u001B[0m )\n\u001B[0;32m     68\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mhub\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     69\u001B[0m     CLOUDFRONT_DISTRIB_PREFIX,\n\u001B[0;32m     70\u001B[0m     HF_MODULES_CACHE,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     96\u001B[0m     try_to_load_from_cache,\n\u001B[0;32m     97\u001B[0m )\n\u001B[0;32m     98\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mimport_utils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     99\u001B[0m     ACCELERATE_MIN_VERSION,\n\u001B[0;32m    100\u001B[0m     ENV_VARS_TRUE_AND_AUTO_VALUES,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    218\u001B[0m     torch_only_method,\n\u001B[0;32m    219\u001B[0m )\n",
      "File \u001B[1;32mE:\\Apps\\anaconda\\envs\\rdf\\Lib\\site-packages\\transformers\\utils\\generic.py:462\u001B[0m\n\u001B[0;32m    458\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mtuple\u001B[39m(\u001B[38;5;28mself\u001B[39m[k] \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkeys())\n\u001B[0;32m    461\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_torch_available():\n\u001B[1;32m--> 462\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_pytree\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01m_torch_pytree\u001B[39;00m\n\u001B[0;32m    464\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_model_output_flatten\u001B[39m(output: ModelOutput) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[List[Any], \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_torch_pytree.Context\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[0;32m    465\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mlist\u001B[39m(output\u001B[38;5;241m.\u001B[39mvalues()), \u001B[38;5;28mlist\u001B[39m(output\u001B[38;5;241m.\u001B[39mkeys())\n",
      "File \u001B[1;32mE:\\Apps\\anaconda\\envs\\rdf\\Lib\\site-packages\\torch\\__init__.py:148\u001B[0m\n\u001B[0;32m    146\u001B[0m                 err \u001B[38;5;241m=\u001B[39m ctypes\u001B[38;5;241m.\u001B[39mWinError(ctypes\u001B[38;5;241m.\u001B[39mget_last_error())\n\u001B[0;32m    147\u001B[0m                 err\u001B[38;5;241m.\u001B[39mstrerror \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m Error loading \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdll\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m or one of its dependencies.\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m--> 148\u001B[0m                 \u001B[38;5;28;01mraise\u001B[39;00m err\n\u001B[0;32m    150\u001B[0m     kernel32\u001B[38;5;241m.\u001B[39mSetErrorMode(prev_error_mode)\n\u001B[0;32m    153\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_preload_cuda_deps\u001B[39m(lib_folder, lib_name):\n",
      "\u001B[1;31mOSError\u001B[0m: [WinError 126] 找不到指定的模块。 Error loading \"E:\\Apps\\anaconda\\envs\\rdf\\Lib\\site-packages\\torch\\lib\\fbgemm.dll\" or one of its dependencies."
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "1b151146-c274-458d-a844-343aaf7977d5",
   "metadata": {
    "id": "1b151146-c274-458d-a844-343aaf7977d5"
   },
   "source": [
    "### Running the model with an example prompt\n",
    "\n",
    "We show that the model can run with an example prompt. First we define the system prompt, which tells the model what character to adopt. Then we give it an instruction to introduce itself. Again, depending on the machine and therefore model used, we use slightly different functions to generate output."
   ]
  },
  {
   "cell_type": "code",
   "id": "c40af130-0e32-4d28-9808-94d8e7345c17",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "id": "c40af130-0e32-4d28-9808-94d8e7345c17",
    "outputId": "1948ffb3-27e8-42e7-858c-f8f109f90e6e"
   },
   "source": [
    "from transformers import pipeline\n",
    "from IPython.display import display\n",
    "\n",
    "SYSTEM_MSG = \"You are a helpful chatbot assistant.\"\n",
    "\n",
    "def generateFromPrompt(promptStr,maxTokens=100):\n",
    "    if platform.processor() == 'arm':\n",
    "      messages = [ {\"role\": \"system\", \"content\": SYSTEM_MSG},\n",
    "              {\"role\": \"user\", \"content\": promptStr}, ]\n",
    "      input_ids = tokenizer.apply_chat_template(messages, add_generation_prompt=True)\n",
    "      prompt = tokenizer.decode(input_ids)\n",
    "      response = generate(model, tokenizer, prompt=prompt, max_tokens=maxTokens)\n",
    "    else:\n",
    "      message = [{\"role\": \"user\", \"content\": promptStr},]\n",
    "      pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer,max_new_tokens=maxTokens)\n",
    "      result = pipe(message)\n",
    "      response = result[0]['generated_text'][1]['content']\n",
    "    return(response)\n",
    "\n",
    "\n",
    "response = generateFromPrompt(\"Please introduce yourself\")\n",
    "\n",
    "print(response+\"...\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d97bc9ea-8528-4591-b30d-a653a7a863c7",
   "metadata": {
    "id": "d97bc9ea-8528-4591-b30d-a653a7a863c7"
   },
   "source": [
    "Now we illustrate performance on a slightly more medically themed topic:"
   ]
  },
  {
   "cell_type": "code",
   "id": "ac53b7a6-f0ea-4597-9550-194dccdc1829",
   "metadata": {
    "id": "ac53b7a6-f0ea-4597-9550-194dccdc1829",
    "outputId": "81327048-4d70-444e-da79-4cdc425aa392"
   },
   "source": [
    "response = generateFromPrompt(\"Please tell me some symptoms of allergies\",maxTokens=200)\n",
    "\n",
    "print(response+\"...\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c3f1f671-353f-450a-a45a-0f5f18e241d1",
   "metadata": {
    "id": "c3f1f671-353f-450a-a45a-0f5f18e241d1"
   },
   "source": [
    "### Using the model to extract themes from narrative texts\n",
    "\n",
    "Here we demonstrate how the model can be used to extract themes from a narrative interview text.\n",
    "\n",
    "This brief interview extract comes from the article Price, T., McColl, E., & Visram, S. (2022). Barriers and facilitators of childhood flu vaccination: The views of parents in North East England. Zeitschrift Fur Gesundheitswissenschaften = Journal of Public Health, 30(11), 2619–2626. https://doi.org/10.1007/s10389-022-01695-2\n",
    "\n",
    "```\n",
    "So can you tell me a kind of your first impressions, your first thoughts around flu? That can be anything from, like, is it a serious illness, what kind of symptoms do you expect to see, kind of anything first thoughts around flu.\n",
    "\n",
    "Participant 12: Yeah, so I know a little bit from my yeah, kind of studies and from work, etc. I think it is quite a serious issue. I think, you know, moving forward as well with the latest pandemic. It could be worse, given the strains on the healthcare system and things like that.But yeah, I think I'm certainly aware of the the seriousness of it for certain at risk groups in particular. So anyone who's already vulnerable or has a long term condition and who are elderly, orvery young, obviously are at higher risk and yeah, you know, the whole aim of the kind of screening program has been to protect those at risk groups up, you know, first and foremost. Also in terms of developmening, herd immunity across the whole community as well. So I've always been for the campaign obviously I understand the evidence base behind it and I always had a flu jab myself. You know, we get provided with that as healthcare workers and as public health workers through our employer. But equally, I think, you know, we see the benefits to, to our children as well in terms of protecting them. But also protecting all the vulnerable people that they come in contact with as well, obviously, when they're at school, when they see elderly grandparents and things like that as well. So, um, as far as signs and symptoms. I think I possibly only had flu once in my life and it may have just been a really bad bug. But I was literally bed bound for it when I was at university for a few, good few days. And so it may have been may have been flu. I think from a symptoms point of view it was just the usual kind of fever, nausea, muscle aches, just high temperature and things like that, really, yeah. Yeah, so they were probably my, my kind of bad symptoms, I would say.\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "747d6507-1895-4ba6-b793-560610e4f015",
   "metadata": {
    "id": "747d6507-1895-4ba6-b793-560610e4f015",
    "outputId": "8336d52a-14ae-4ca7-ce92-4de956d1300e"
   },
   "source": [
    "interviewExtract = \"\"\"\n",
    "So can you tell me a kind of your first impressions, your first thoughts around flu? That can be anything from, like, is it a serious illness, what kind of symptoms do you expect to see, kind of anything first thoughts around flu.\n",
    "\n",
    "Participant 12: Yeah, so I know a little bit from my yeah, kind of studies and from work, etc. I think it is quite a serious issue. I think, you know, moving forward as well with the latest pandemic. It could be worse, given the strains on the healthcare system and things like that.But yeah, I think I'm certainly aware of the the seriousness of it for certain at risk groups in particular. So anyone who's already vulnerable or has a long term condition and who are elderly, orvery young, obviously are at higher risk and yeah, you know, the whole aim of the kind of screening program has been to protect those at risk groups up, you know, first and foremost. Also in terms of developmening, herd immunity across the whole community as well. So I've always been for the campaign obviously I understand the evidence base behind it and I always had a flu jab myself. You know, we get provided with that as healthcare workers and as public health workers through our employer. But equally, I think, you know, we see the benefits to, to our children as well in terms of protecting them. But also protecting all the vulnerable people that they come in contact with as well, obviously, when they're at school, when they see elderly grandparents and things like that as well. So, um, as far as signs and symptoms. I think I possibly only had flu once in my life and it may have just been a really bad bug. But I was literally bed bound for it when I was at university for a few, good few days. And so it may have been may have been flu. I think from a symptoms point of view it was just the usual kind of fever, nausea, muscle aches, just high temperature and things like that, really, yeah. Yeah, so they were probably my, my kind of bad symptoms, I would say.\n",
    "\"\"\"\n",
    "\n",
    "response = generateFromPrompt(\"Please identify some themes in the following interview transcript: ' \"+interviewExtract+\"'\",maxTokens=200)\n",
    "\n",
    "print(response+\"...\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c131359e-0187-4e58-8996-4d50e2b18555",
   "metadata": {
    "id": "c131359e-0187-4e58-8996-4d50e2b18555"
   },
   "source": [
    "### Exploring structural aspects of the interview text\n",
    "\n",
    "We can also try to use the LM to extract structural aspects of the interview speech such as how confident the speaker is."
   ]
  },
  {
   "cell_type": "code",
   "id": "7e93aaa5-6562-4eb8-a906-b33bb1705d79",
   "metadata": {
    "id": "7e93aaa5-6562-4eb8-a906-b33bb1705d79",
    "outputId": "963a44fd-6e93-4ac1-f295-1a422e6260db",
    "scrolled": true
   },
   "source": [
    "response = generateFromPrompt(\"Please describe how confident the interviewee is in the following interview, with motivation: ' \"+interviewExtract+\"'\",maxTokens=200)\n",
    "\n",
    "display(response+\"...\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "59b40dea-6f28-42fe-a01c-f25e1835848b",
   "metadata": {
    "id": "59b40dea-6f28-42fe-a01c-f25e1835848b"
   },
   "source": [
    "### Exploring emotional aspects of the interview text\n",
    "\n",
    "We can explore any emotional dimensions that are present in the narrative text."
   ]
  },
  {
   "cell_type": "code",
   "id": "821be237-4621-4bad-9910-dd3ad7f5ce7c",
   "metadata": {
    "id": "821be237-4621-4bad-9910-dd3ad7f5ce7c",
    "outputId": "e9991062-cfd6-4668-b3b3-e62264da99d7"
   },
   "source": [
    "response = generateFromPrompt(\"Please describe the sentiment and any emotions of the interviewee in the following interview, with motivation: ' \"+interviewExtract+\"'\",maxTokens=200)\n",
    "\n",
    "print(response+\"...\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5f3bcbcd-8122-4163-95f1-c5b8d82d20db",
   "metadata": {
    "id": "5f3bcbcd-8122-4163-95f1-c5b8d82d20db"
   },
   "source": [
    "### Extracting information according to a predefined schema\n",
    "\n",
    "The original study from which this transcript has been sourced harnessed the COM-B theory of behaviour change to frame the research study into perspectives on childhood vaccination. We can similarly use the language model to extract examples of those theoretical elements."
   ]
  },
  {
   "cell_type": "code",
   "id": "d2a38602-d521-4fff-b5dc-d9dea1e992fd",
   "metadata": {
    "id": "d2a38602-d521-4fff-b5dc-d9dea1e992fd",
    "outputId": "d88ddaa4-c9d5-4a12-849f-293a1050de7b"
   },
   "source": [
    "response = generateFromPrompt(\"Please extract examples of COM-B (capability, opportunity, and motivation) elements in the following interview: ' \"+interviewExtract+\"'\",maxTokens=400)\n",
    "\n",
    "print(response+\"...\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
